{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import json\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "import SimpleITK as itk\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patheffects as path_effects\n",
    "sns.set_style(\"whitegrid\")\n",
    "from src.utils import save_json, subfiles, join, maybe_mkdir_p, reconstruct_seg_df_from_json, reconstruct_calib_df_from_json, reconstruct_UED_df_from_json\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistics for different studies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.multitest import multipletests\n",
    "groups = ['Baseline','No TTA', 'MC Dropout','Ensemble','Snapshots', \"Complex\" ,'PhiSeg']\n",
    "from scipy.stats import wilcoxon\n",
    "def calcualte_test(x, y, method = wilcoxon):\n",
    "    # method could also be pearsonr\n",
    "    nas = np.logical_or(np.isnan(x), np.isnan(y)) # remove nan\n",
    "\n",
    "    return method(x[~nas], y[~nas])\n",
    "\n",
    "# if data is screwed\n",
    "def bootstrap_confidence_interval(data, func=np.mean, confidence=95, size=10000):\n",
    "    \"\"\"\n",
    "    func could be np.mean/np.median\n",
    "    \"\"\"\n",
    "    \n",
    "    bs_replicates = np.empty(size)\n",
    "    \n",
    "    # Create bootstrap replicates as much as size\n",
    "    for i in range(size):\n",
    "        # Create a bootstrap sample\n",
    "        bs_sample = np.random.choice(data,size=len(data))\n",
    "        # Get bootstrap replicate and append to bs_replicates\n",
    "        bs_replicates[i] = func(bs_sample)\n",
    "        \n",
    "    conf_interval = np.percentile(bs_replicates,[100-confidence,confidence])\n",
    "    np.round(func(bs_replicates), 2), tuple(np.round(conf_interval,2))\n",
    "    m = np.round(func(bs_replicates), 2)\n",
    "    ci0, ci1 = np.round(conf_interval,2)\n",
    "    #return_str = str(m)+'('+str(ci0)+'-'+ str(ci1)+')'\n",
    "    return_str = f'{m:.2f}({ci0:.2f}-{ci1:.2f})'\n",
    "    return return_str\n",
    "\n",
    "\n",
    "def print_tests(data, exp):\n",
    "    \"\"\"\n",
    "    !!!baseline data frist!!!\n",
    "    \"\"\"\n",
    "    print(exp)\n",
    "    for gtv in [\"GTV-T\", \"GTV-N\"]:\n",
    "        print(gtv)\n",
    "        pvalues = [] \n",
    "        means = []\n",
    "        for group in groups:\n",
    "            #print(\"----------------------\")\n",
    "            #\n",
    "            test_all_data = data[((data[\"Ucertainty estimation methods\"]==group) | (data[\"Ucertainty estimation methods\"]==\"Baseline\")) & (data[\"GTV\"]==gtv) ]\n",
    "            base = test_all_data[(test_all_data[\"Ucertainty estimation methods\"]==\"Baseline\")][exp].astype({exp: float})\n",
    "            test = test_all_data[(test_all_data[\"Ucertainty estimation methods\"]==group)][exp].astype({exp: float})\n",
    "            means.append(str(bootstrap_confidence_interval(test.dropna())))\n",
    "            if group == \"Baseline\":\n",
    "                #pvalues.append(1)\n",
    "                continue\n",
    "\n",
    "            s, p = calcualte_test(base.values,test.values)\n",
    "            # = np.round(p, 5)\n",
    "            #print(type(p), p)\n",
    "            pvalues.append(p)\n",
    "        print(\"pvalues before correction: \", pvalues)\n",
    "        corrected_pvalues = multipletests(pvalues)\n",
    "        #print(\"pvalues after correction:\", corrected_pvalues[0])\n",
    "        corrected = [1]+ list(corrected_pvalues[1])\n",
    "        print(\"pvalues after correction:\", corrected)\n",
    "\n",
    "        for i, p in enumerate(corrected):\n",
    "            if p < 0.001:\n",
    "                print(means[i]+\"***\")\n",
    "            elif p < 0.01:\n",
    "                print(means[i]+\"**\")\n",
    "            elif p < 0.05:\n",
    "                print(means[i]+\"*\")\n",
    "            else:\n",
    "                #print(str(np.round(p, 3)))\n",
    "                p = np.round(p, 4)\n",
    "                print(means[i]+str(p))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Segmentation performance comparision \n",
    "Internal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "## directorys for internal  probability maps \n",
    "\n",
    "DROP2_PMAPS=\"/data/jintao/nnUNet/nnUNet_results/nnUNet/3d_fullres/Task901_AUH/nnUNetTrainerV2_dropout__nnUNetPlansv2.1/prob_maps/Task901_AUH/imagesTs\"\n",
    "NNUNET_PMAPS=\"/data/jintao/nnUNet/nnUNet_results/nnUNet/3d_fullres/Task901_AUH/nnUNetTrainerV2__nnUNetPlansv2.1/prob_maps/Task901_AUH/imagesTs\"\n",
    "PH_PMAPS=\"/data/jintao/nnUNet/nnUNet_results/nnUNet/3d_fullres/Task901_AUH/nnUNetTrainerV2_PhiSeg__nnUNetPlansv2.1/prob_maps/Task901_AUH/imagesTs\"\n",
    "PH_GAMM_PMAP=\"/data/jintao/nnUNet/nnUNet_results/nnUNet/3d_fullres/Task901_AUH/nnUNetTrainerV2_PhiSeg_gamma__nnUNetPlansv2.1/prob_maps/Task901_AUH/imagesTs\"\n",
    "\n",
    "studies = [\n",
    "join(NNUNET_PMAPS,'f0_tta'),\n",
    "join(NNUNET_PMAPS,'f0'),\n",
    "join(DROP2_PMAPS,'f0_mc10_tta')\n",
    ",join(NNUNET_PMAPS,'f01234_tta')\n",
    ",join(DROP2_PMAPS,'f0_tta_snap')\n",
    ",join(DROP2_PMAPS,'f01234_mc10_tta_snap')\n",
    ",join(PH_PMAPS,'f01234_tta')\n",
    "]\n",
    "\n",
    "groups = ['Baseline','No TTA', 'MC Dropout','Ensemble','Snapshots', \"Complex\" ,'PhiSeg']\n",
    "for i, study in enumerate(studies):\n",
    "    gtvt_seg, gtvn_seg  = reconstruct_seg_df_from_json(study)\n",
    "    df_seg_t = pd.DataFrame.from_dict(gtvt_seg).T\n",
    "    df_seg_n = pd.DataFrame.from_dict(gtvn_seg).T\n",
    "\n",
    "    dft = df_seg_t\n",
    "    dfn = df_seg_n\n",
    "\n",
    "    dft['Ucertainty estimation methods'] = groups[i]\n",
    "    dfn['Ucertainty estimation methods'] = groups[i]\n",
    "\n",
    "    dft.index.names = ['PatientID']\n",
    "    dfn.index.names = ['PatientID']\n",
    "    dft= dft.reset_index(drop=False)\n",
    "    dfn= dfn.reset_index(drop=False)\n",
    "\n",
    "    if i == 0:\n",
    "        dft_all_correct = dft\n",
    "        dfn_all_correct = dfn\n",
    "    else:\n",
    "        dft_all_correct = pd.concat([dft_all_correct, dft])\n",
    "        dfn_all_correct = pd.concat([dfn_all_correct, dfn])\n",
    "\n",
    "all_seg_internal = pd.concat([dft_all_correct, dfn_all_correct])\n",
    "all_seg_internal= all_seg_internal.reset_index(drop=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DSC\n",
      "GTV-T\n",
      "pvalues before correction:  [0.008971217549269767, 0.13180683322738812, 0.002308022296133644, 0.04035775996940854, 0.4515773027033496, 0.00772192657235769]\n",
      "pvalues after correction: [1, 0.03801793805373229, 0.24624062516934372, 0.013768474742922695, 0.11625276619168756, 0.4515773027033496, 0.03801793805373229]\n",
      "0.68(0.64-0.71)1\n",
      "0.67(0.63-0.70)*\n",
      "0.67(0.64-0.71)0.2462\n",
      "0.69(0.65-0.72)*\n",
      "0.67(0.63-0.70)0.1163\n",
      "0.67(0.63-0.71)0.4516\n",
      "0.63(0.58-0.67)*\n",
      "GTV-N\n",
      "pvalues before correction:  [0.011697936760166063, 0.10313682673243209, 0.005390649509551264, 0.3744737555342701, 0.21150382409725055, 0.005199335321500139]\n",
      "pvalues after correction: [1, 0.04597708103169247, 0.27859595268392423, 0.03079331575494367, 0.3782737805867404, 0.3782737805867404, 0.03079331575494367]\n",
      "0.63(0.57-0.69)1\n",
      "0.63(0.57-0.69)*\n",
      "0.63(0.57-0.69)0.2786\n",
      "0.64(0.58-0.70)*\n",
      "0.62(0.56-0.68)0.3783\n",
      "0.64(0.58-0.70)0.3783\n",
      "0.64(0.58-0.70)*\n"
     ]
    }
   ],
   "source": [
    "exp= 'DSC' \n",
    "#exp= 'HD95 (mm)'\n",
    "#exp= 'Mean Surface Distance (mm)'\n",
    "#exp= 'Surface Dice 2mm'\n",
    "\n",
    "print_tests(all_seg_internal, exp)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "External"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Surface Dice 2mm\n",
      "GTV-T\n",
      "pvalues before correction:  [0.049309693183975635, 0.10734313335396876, 2.0498904903972427e-08, 0.0004754376320679146, 1.0957672261788388e-07, 0.3491034180382393]\n",
      "pvalues after correction: [1, 0.14075463587469092, 0.2031637184296896, 1.229934231207582e-07, 0.0019003947124421267, 5.478834930188512e-07, 0.3491034180382393]\n",
      "0.55(0.53-0.57)\n",
      "0.53(0.50-0.55)\n",
      "0.54(0.52-0.57)\n",
      "0.58(0.55-0.60)***\n",
      "0.55(0.53-0.58)**\n",
      "0.58(0.56-0.60)***\n",
      "0.53(0.51-0.56)\n",
      "GTV-N\n",
      "pvalues before correction:  [0.004563590323981993, 0.16680243408877604, 3.0479477750938654e-07, 0.49053175526994763, 0.12838190966958027, 3.11428497349035e-11]\n",
      "pvalues after correction: [1, 0.018129782894158668, 0.337815964505617, 1.523972958548652e-06, 0.49053175526994763, 0.337815964505617, 1.8685709839487287e-10]\n",
      "0.65(0.62-0.67)\n",
      "0.63(0.61-0.66)*\n",
      "0.63(0.60-0.66)\n",
      "0.68(0.65-0.70)***\n",
      "0.63(0.61-0.66)\n",
      "0.67(0.64-0.69)\n",
      "0.61(0.58-0.63)***\n"
     ]
    }
   ],
   "source": [
    "## directorys for external probability maps \n",
    "\n",
    "DROP2_PMAPS=\"/data/jintao/nnUNet/nnUNet_results/nnUNet/3d_fullres/Task901_AUH/nnUNetTrainerV2_dropout__nnUNetPlansv2.1/prob_maps/Task711_NKI_origin/imagesAll_ct_correct\"\n",
    "NNUNET_PMAPS=\"/data/jintao/nnUNet/nnUNet_results/nnUNet/3d_fullres/Task901_AUH/nnUNetTrainerV2__nnUNetPlansv2.1/prob_maps/Task711_NKI_origin/imagesAll_ct_correct\"\n",
    "PH_PMAPS=\"/data/jintao/nnUNet/nnUNet_results/nnUNet/3d_fullres/Task901_AUH/nnUNetTrainerV2_PhiSeg__nnUNetPlansv2.1/prob_maps/Task711_NKI_origin/imagesAll_ct_correct\"\n",
    "PH_GAMM_PMAP=\"/data/jintao/nnUNet/nnUNet_results/nnUNet/3d_fullres/Task901_AUH/nnUNetTrainerV2_PhiSeg_gamma__nnUNetPlansv2.1/prob_maps/Task711_NKI_origin/imagesAll_ct_correct\"\n",
    "\n",
    "studies = [\n",
    "join(NNUNET_PMAPS,'f0_tta'),\n",
    "join(NNUNET_PMAPS,'f0'),\n",
    "join(DROP2_PMAPS,'f0_mc10_tta')\n",
    ",join(NNUNET_PMAPS,'f01234_tta')\n",
    ",join(DROP2_PMAPS,'f0_tta_snap')\n",
    ",join(DROP2_PMAPS,'f01234_mc10_tta_snap')\n",
    ",join(PH_PMAPS,'f01234_tta')\n",
    "]\n",
    "#,join(PH_GAMM_PMAP,'f0_tta')]\n",
    "\n",
    "\n",
    "groups = ['Baseline', 'No TTA','MC Dropout','Ensemble','Snapshots', \"Complex\" ,'PhiSeg']\n",
    "for i, study in enumerate(studies):\n",
    "    gtvt_seg, gtvn_seg  = reconstruct_seg_df_from_json(study)\n",
    "    df_seg_t = pd.DataFrame.from_dict(gtvt_seg).T\n",
    "    df_seg_n = pd.DataFrame.from_dict(gtvn_seg).T\n",
    "\n",
    "    dft = df_seg_t\n",
    "    dfn = df_seg_n\n",
    "\n",
    "    dft['Ucertainty estimation methods'] = groups[i]\n",
    "    dfn['Ucertainty estimation methods'] = groups[i]\n",
    "\n",
    "    dft.index.names = ['PatientID']\n",
    "    dfn.index.names = ['PatientID']\n",
    "    dft= dft.reset_index(drop=False)\n",
    "    dfn= dfn.reset_index(drop=False)\n",
    "\n",
    "    if i == 0:\n",
    "        dft_all_correct = dft\n",
    "        dfn_all_correct = dfn\n",
    "    else:\n",
    "        dft_all_correct = pd.concat([dft_all_correct, dft])\n",
    "        dfn_all_correct = pd.concat([dfn_all_correct, dfn])\n",
    "\n",
    "\n",
    "all_seg_external = pd.concat([dft_all_correct, dfn_all_correct])\n",
    "all_seg_external= all_seg_external.reset_index(drop=False)\n",
    "\n",
    "# exp= 'DSC' \n",
    "# exp= 'HD95 (mm)'\n",
    "# exp= 'Mean Surface Distance (mm)'\n",
    "exp= 'Surface Dice 2mm'\n",
    "print_tests(all_seg_external, exp)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calibarion performance comparision \n",
    "Internal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "groups = ['Baseline','No TTA', 'MC Dropout','Ensemble','Snapshots',\"Complex\", 'PhiSeg' ]\n",
    "## directorys for main internal probability maps \n",
    "\n",
    "DROP2_PMAPS=\"/data/jintao/nnUNet/nnUNet_results/nnUNet/3d_fullres/Task901_AUH/nnUNetTrainerV2_dropout__nnUNetPlansv2.1/prob_maps/Task901_AUH/imagesTs\"\n",
    "NNUNET_PMAPS=\"/data/jintao/nnUNet/nnUNet_results/nnUNet/3d_fullres/Task901_AUH/nnUNetTrainerV2__nnUNetPlansv2.1/prob_maps/Task901_AUH/imagesTs\"\n",
    "PH_PMAP=\"/data/jintao/nnUNet/nnUNet_results/nnUNet/3d_fullres/Task901_AUH/nnUNetTrainerV2_PhiSeg__nnUNetPlansv2.1/prob_maps/Task901_AUH/imagesTs\"\n",
    "PH_GAMM_PMAP=\"/data/jintao/nnUNet/nnUNet_results/nnUNet/3d_fullres/Task901_AUH/nnUNetTrainerV2_PhiSeg_gamma__nnUNetPlansv2.1/prob_maps/Task901_AUH/imagesTs\"\n",
    "\n",
    "studies = [\n",
    "join(NNUNET_PMAPS,'f0_tta'),\n",
    "join(NNUNET_PMAPS,'f0'),\n",
    "join(DROP2_PMAPS,'f0_mc10_tta')\n",
    ",join(NNUNET_PMAPS,'f01234_tta')\n",
    "#,join(NNUNET_PMAPS,'f012456_tta')\n",
    ",join(DROP2_PMAPS,'f0_tta_snap')\n",
    ",join(DROP2_PMAPS,'f01234_mc10_tta_snap')\n",
    ",join(PH_PMAP,'f01234_tta')\n",
    "\n",
    "]\n",
    "#,join(PH_GAMM_PMAP,'f0_tta')]\n",
    "\n",
    "for i, study in enumerate(studies):\n",
    "    gtvt_calib, gtvn_calib  = reconstruct_calib_df_from_json(study)\n",
    "    df_cal_t = pd.DataFrame.from_dict(gtvt_calib).T\n",
    "    df_cal_n = pd.DataFrame.from_dict(gtvn_calib).T\n",
    "\n",
    "    df_cal_t['GTV'] = 'GTV-T'\n",
    "    \n",
    "    df_cal_n['GTV'] = 'GTV-N'\n",
    "\n",
    "    dft = df_cal_t\n",
    "    dfn = df_cal_n\n",
    "    \n",
    "    dft['Ucertainty estimation methods'] = groups[i]\n",
    "    dfn['Ucertainty estimation methods'] = groups[i]\n",
    "    dft.index.names = ['PatientID']\n",
    "    dfn.index.names = ['PatientID']\n",
    "    dft= dft.reset_index(drop=False)\n",
    "    dfn= dfn.reset_index(drop=False)\n",
    "\n",
    "    if i == 0:\n",
    "        dft_all = dft\n",
    "        dfn_all = dfn\n",
    "    else:\n",
    "        dft_all = pd.concat([dft_all, dft])\n",
    "        dfn_all = pd.concat([dfn_all, dfn])\n",
    "\n",
    "all_calib_internal = pd.concat([dft_all, dfn_all])\n",
    "all_calib_internal= all_calib_internal.reset_index(drop=True)\n",
    "\n",
    "## directorys for external probability maps \n",
    "\n",
    "DROP2_PMAPS_EXT=\"/data/jintao/nnUNet/nnUNet_results/nnUNet/3d_fullres/Task901_AUH/nnUNetTrainerV2_dropout__nnUNetPlansv2.1/prob_maps/Task711_NKI_origin/imagesAll_ct_correct\"\n",
    "NNUNET_PMAPS_EXT=\"/data/jintao/nnUNet/nnUNet_results/nnUNet/3d_fullres/Task901_AUH/nnUNetTrainerV2__nnUNetPlansv2.1/prob_maps/Task711_NKI_origin/imagesAll_ct_correct\"\n",
    "PH_PMAPS_EXT=\"/data/jintao/nnUNet/nnUNet_results/nnUNet/3d_fullres/Task901_AUH/nnUNetTrainerV2_PhiSeg__nnUNetPlansv2.1/prob_maps/Task711_NKI_origin/imagesAll_ct_correct\"\n",
    "PH_GAMM_PMAPS_EXT=\"/data/jintao/nnUNet/nnUNet_results/nnUNet/3d_fullres/Task901_AUH/nnUNetTrainerV2_PhiSeg_gamma__nnUNetPlansv2.1/prob_maps/Task711_NKI_origin/imagesAll_ct_correct\"\n",
    "\n",
    "studies = [\n",
    "join(NNUNET_PMAPS_EXT,'f0_tta'),#X8\n",
    "join(NNUNET_PMAPS_EXT,'f0'), #X1\n",
    "join(DROP2_PMAPS_EXT,'f0_mc10_tta') #X80\n",
    ",join(NNUNET_PMAPS_EXT,'f01234_tta') #X40\n",
    "#,join(NNUNET_PMAPS_EXT,'f012456_tta')\n",
    ",join(DROP2_PMAPS_EXT,'f0_tta_snap') #X40\n",
    ",join(DROP2_PMAPS_EXT,'f01234_mc10_tta_snap') #X2000\n",
    ",join(PH_PMAPS_EXT,'f01234_tta') #X40\n",
    "]\n",
    "\n",
    "for i, study in enumerate(studies):\n",
    "    gtvt_calib, gtvn_calib  = reconstruct_calib_df_from_json(study)\n",
    "    df_cal_t = pd.DataFrame.from_dict(gtvt_calib).T\n",
    "    df_cal_n = pd.DataFrame.from_dict(gtvn_calib).T\n",
    "\n",
    "    df_cal_t['GTV'] = 'GTV-T'\n",
    "    df_cal_n['GTV'] = 'GTV-N'\n",
    "    \n",
    "    dft = df_cal_t\n",
    "    dfn = df_cal_n\n",
    "\n",
    "    dft['Ucertainty estimation methods'] = groups[i]\n",
    "    dfn['Ucertainty estimation methods'] = groups[i]\n",
    "    dft.index.names = ['PatientID']\n",
    "    dfn.index.names = ['PatientID']\n",
    "    dft= dft.reset_index(drop=False)\n",
    "    dfn= dfn.reset_index(drop=False)\n",
    "\n",
    "    if i == 0:\n",
    "        dft_all = dft\n",
    "        dfn_all = dfn\n",
    "    else:\n",
    "        dft_all = pd.concat([dft_all, dft])\n",
    "        dfn_all = pd.concat([dfn_all, dfn])\n",
    "        dft_all= dft_all.reset_index(drop=True)\n",
    "        dfn_all= dfn_all.reset_index(drop=True)\n",
    "\n",
    "\n",
    "all_calib_external = pd.concat([dft_all, dfn_all])\n",
    "all_calib_external= all_calib_external.reset_index(drop=True)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "internal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected Calibration Error\n",
      "GTV-T\n",
      "pvalues before correction:  [1.218119098708288e-17, 0.02263847169630356, 3.369310934424041e-14, 2.571044027114986e-09, 5.853697609433029e-14, 1.3533873592059003e-10]\n",
      "pvalues after correction: [1, 7.308714592249727e-17, 0.02263847169630356, 1.684655467211907e-13, 5.142088047619705e-09, 2.341479043773006e-13, 4.0601620770682035e-10]\n",
      "0.28(0.26-0.31)\n",
      "0.36(0.33-0.39)***\n",
      "0.26(0.24-0.28)*\n",
      "0.24(0.22-0.27)***\n",
      "0.23(0.20-0.25)***\n",
      "0.21(0.18-0.23)***\n",
      "0.18(0.15-0.22)***\n",
      "GTV-N\n",
      "pvalues before correction:  [1.3354633299502592e-11, 0.9978067952264031, 2.0563938125435043e-09, 7.81531520340445e-05, 3.293749895989552e-11, 2.182312842251161e-11]\n",
      "pvalues after correction: [1, 8.012779979434034e-11, 0.9978067952264031, 6.169181424944246e-09, 0.00015630019615291615, 1.317499958330728e-10, 1.0911564210779555e-10]\n",
      "0.26(0.23-0.30)\n",
      "0.31(0.27-0.35)***\n",
      "0.25(0.22-0.28)\n",
      "0.24(0.20-0.27)***\n",
      "0.22(0.20-0.25)***\n",
      "0.21(0.18-0.23)***\n",
      "0.17(0.13-0.21)***\n"
     ]
    }
   ],
   "source": [
    "# exp= 'Brier Score' \n",
    "exp= 'Expected Calibration Error'\n",
    "\n",
    "print_tests(all_calib_internal, exp)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "external"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected Calibration Error\n",
      "GTV-T\n",
      "pvalues before correction:  [8.114841775971355e-36, 6.96010760470907e-09, 4.239576622725384e-27, 1.3607751916168863e-25, 3.515473118108575e-35, 2.5860796143776974e-28]\n",
      "pvalues after correction: [1, 4.868905065582814e-35, 6.96010760470907e-09, 1.2718729868176152e-26, 2.7215503832337726e-25, 1.7577365590542875e-34, 1.034431845751079e-27]\n",
      "0.36(0.34-0.38)\n",
      "0.45(0.43-0.47)***\n",
      "0.32(0.30-0.34)***\n",
      "0.30(0.28-0.31)***\n",
      "0.28(0.26-0.29)***\n",
      "0.24(0.22-0.25)***\n",
      "0.23(0.21-0.25)***\n",
      "GTV-N\n",
      "pvalues before correction:  [1.843470407957155e-30, 0.002466902172726311, 7.192241469673306e-21, 2.862082052875858e-17, 4.3677073664399924e-26, 2.3746676417965406e-16]\n",
      "pvalues after correction: [1, 1.106082244774293e-29, 0.002466902172726311, 2.876896587869322e-20, 8.586246158627573e-17, 2.1838536832199963e-25, 4.749335283593081e-16]\n",
      "0.35(0.32-0.37)\n",
      "0.41(0.39-0.44)***\n",
      "0.33(0.31-0.35)**\n",
      "0.31(0.28-0.33)***\n",
      "0.29(0.27-0.31)***\n",
      "0.27(0.25-0.29)***\n",
      "0.27(0.25-0.30)***\n"
     ]
    }
   ],
   "source": [
    "# exp= 'Brier Score' \n",
    "exp= 'Expected Calibration Error'\n",
    "\n",
    "print_tests(all_calib_external, exp)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Uncertainty Error Overlap Degree (UED) comparision\n",
    "Internal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PatientID</th>\n",
       "      <th>UED</th>\n",
       "      <th>UED_volume</th>\n",
       "      <th>UED_th</th>\n",
       "      <th>FND</th>\n",
       "      <th>FND_volume</th>\n",
       "      <th>FND_th</th>\n",
       "      <th>FPD</th>\n",
       "      <th>FPD_volume</th>\n",
       "      <th>FPD_th</th>\n",
       "      <th>GTV</th>\n",
       "      <th>Ucertainty estimation methods</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NKI_002</td>\n",
       "      <td>0.139333</td>\n",
       "      <td>11878</td>\n",
       "      <td>7</td>\n",
       "      <td>0.06278</td>\n",
       "      <td>11085</td>\n",
       "      <td>7</td>\n",
       "      <td>0.155526</td>\n",
       "      <td>793</td>\n",
       "      <td>7</td>\n",
       "      <td>GTV-T</td>\n",
       "      <td>Baseline</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NKI_003</td>\n",
       "      <td>0.270218</td>\n",
       "      <td>5972</td>\n",
       "      <td>7</td>\n",
       "      <td>0.23644</td>\n",
       "      <td>4295</td>\n",
       "      <td>7</td>\n",
       "      <td>0.121432</td>\n",
       "      <td>1677</td>\n",
       "      <td>7</td>\n",
       "      <td>GTV-T</td>\n",
       "      <td>Baseline</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NKI_005</td>\n",
       "      <td>0.407866</td>\n",
       "      <td>6621</td>\n",
       "      <td>7</td>\n",
       "      <td>0.32537</td>\n",
       "      <td>4966</td>\n",
       "      <td>7</td>\n",
       "      <td>0.11124</td>\n",
       "      <td>1655</td>\n",
       "      <td>7</td>\n",
       "      <td>GTV-T</td>\n",
       "      <td>Baseline</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NKI_007</td>\n",
       "      <td>0.323929</td>\n",
       "      <td>5541</td>\n",
       "      <td>7</td>\n",
       "      <td>0.21167</td>\n",
       "      <td>3951</td>\n",
       "      <td>7</td>\n",
       "      <td>0.206078</td>\n",
       "      <td>1590</td>\n",
       "      <td>7</td>\n",
       "      <td>GTV-T</td>\n",
       "      <td>Baseline</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NKI_010</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>GTV-T</td>\n",
       "      <td>Baseline</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3299</th>\n",
       "      <td>NKI_333</td>\n",
       "      <td>0.369438</td>\n",
       "      <td>12535</td>\n",
       "      <td>7</td>\n",
       "      <td>0.338453</td>\n",
       "      <td>9150</td>\n",
       "      <td>7</td>\n",
       "      <td>0.436776</td>\n",
       "      <td>3385</td>\n",
       "      <td>7</td>\n",
       "      <td>GTV-N</td>\n",
       "      <td>PhiSeg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3300</th>\n",
       "      <td>NKI_334</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5098</td>\n",
       "      <td>7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5098</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>GTV-N</td>\n",
       "      <td>PhiSeg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3301</th>\n",
       "      <td>NKI_336</td>\n",
       "      <td>0.309284</td>\n",
       "      <td>6902</td>\n",
       "      <td>7</td>\n",
       "      <td>0.315542</td>\n",
       "      <td>5064</td>\n",
       "      <td>7</td>\n",
       "      <td>0.259931</td>\n",
       "      <td>1838</td>\n",
       "      <td>7</td>\n",
       "      <td>GTV-N</td>\n",
       "      <td>PhiSeg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3302</th>\n",
       "      <td>NKI_338</td>\n",
       "      <td>0.388861</td>\n",
       "      <td>26730</td>\n",
       "      <td>7</td>\n",
       "      <td>0.270884</td>\n",
       "      <td>19457</td>\n",
       "      <td>7</td>\n",
       "      <td>0.602775</td>\n",
       "      <td>7273</td>\n",
       "      <td>7</td>\n",
       "      <td>GTV-N</td>\n",
       "      <td>PhiSeg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3303</th>\n",
       "      <td>NKI_339</td>\n",
       "      <td>0.227287</td>\n",
       "      <td>37833</td>\n",
       "      <td>7</td>\n",
       "      <td>0.157172</td>\n",
       "      <td>34262</td>\n",
       "      <td>7</td>\n",
       "      <td>0.588394</td>\n",
       "      <td>3571</td>\n",
       "      <td>7</td>\n",
       "      <td>GTV-N</td>\n",
       "      <td>PhiSeg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3304 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PatientID       UED UED_volume UED_th       FND FND_volume FND_th  \\\n",
       "0      NKI_002  0.139333      11878      7   0.06278      11085      7   \n",
       "1      NKI_003  0.270218       5972      7   0.23644       4295      7   \n",
       "2      NKI_005  0.407866       6621      7   0.32537       4966      7   \n",
       "3      NKI_007  0.323929       5541      7   0.21167       3951      7   \n",
       "4      NKI_010       NaN          0      0       NaN          0      0   \n",
       "...        ...       ...        ...    ...       ...        ...    ...   \n",
       "3299   NKI_333  0.369438      12535      7  0.338453       9150      7   \n",
       "3300   NKI_334       0.0       5098      7       0.0       5098      7   \n",
       "3301   NKI_336  0.309284       6902      7  0.315542       5064      7   \n",
       "3302   NKI_338  0.388861      26730      7  0.270884      19457      7   \n",
       "3303   NKI_339  0.227287      37833      7  0.157172      34262      7   \n",
       "\n",
       "           FPD FPD_volume FPD_th    GTV Ucertainty estimation methods  \n",
       "0     0.155526        793      7  GTV-T                      Baseline  \n",
       "1     0.121432       1677      7  GTV-T                      Baseline  \n",
       "2      0.11124       1655      7  GTV-T                      Baseline  \n",
       "3     0.206078       1590      7  GTV-T                      Baseline  \n",
       "4          NaN          0      0  GTV-T                      Baseline  \n",
       "...        ...        ...    ...    ...                           ...  \n",
       "3299  0.436776       3385      7  GTV-N                        PhiSeg  \n",
       "3300       NaN          0      0  GTV-N                        PhiSeg  \n",
       "3301  0.259931       1838      7  GTV-N                        PhiSeg  \n",
       "3302  0.602775       7273      7  GTV-N                        PhiSeg  \n",
       "3303  0.588394       3571      7  GTV-N                        PhiSeg  \n",
       "\n",
       "[3304 rows x 12 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## directorys for main internal probability maps \n",
    "\n",
    "NNUNET_UREGIONS=\"/data/jintao/nnUNet/nnUNet_results/nnUNet/3d_fullres/Task901_AUH/nnUNetTrainerV2__nnUNetPlansv2.1/u_regions/Task901_AUH/imagesTs\"\n",
    "DROP1_UREGIONS=\"/data/jintao/nnUNet/nnUNet_results/nnUNet/3d_fullres/Task901_AUH/nnUNetTrainerV2_dropout1__nnUNetPlansv2.1/u_regions/Task901_AUH/imagesTs\"\n",
    "DROP2_UREGIONS=\"/data/jintao/nnUNet/nnUNet_results/nnUNet/3d_fullres/Task901_AUH/nnUNetTrainerV2_dropout__nnUNetPlansv2.1/u_regions/Task901_AUH/imagesTs\"\n",
    "DROP3_UREGIONS=\"/data/jintao/nnUNet/nnUNet_results/nnUNet/3d_fullres/Task901_AUH/nnUNetTrainerV2_dropout3__nnUNetPlansv2.1/u_regions/Task901_AUH/imagesTs\"\n",
    "DROP5_UREGIONS=\"/data/jintao/nnUNet/nnUNet_results/nnUNet/3d_fullres/Task901_AUH/nnUNetTrainerV2_dropout5__nnUNetPlansv2.1/u_regions/Task901_AUH/imagesTs\"\n",
    "\n",
    "PHISEG_UREGIONS = \"/data/jintao/nnUNet/nnUNet_results/nnUNet/3d_fullres/Task901_AUH/nnUNetTrainerV2_PhiSeg__nnUNetPlansv2.1/u_regions/Task901_AUH/imagesTs\"\n",
    "PHISEG_GAMMA_UREGIONS= \"/data/jintao/nnUNet/nnUNet_results/nnUNet/3d_fullres/Task901_AUH/nnUNetTrainerV2_PhiSeg_gamma__nnUNetPlansv2.1/u_regions/Task901_AUH/imagesTs\"\n",
    "\n",
    "studies = [\n",
    "join(NNUNET_UREGIONS,'f0_tta'),\n",
    "join(NNUNET_UREGIONS,'f0'),\n",
    "join(DROP2_UREGIONS,'f0_mc10_tta')\n",
    ",join(NNUNET_UREGIONS,'f01234_tta')\n",
    "#,join(NNUNET_PMAPS,'f012456_tta')\n",
    ",join(DROP2_UREGIONS,'f0_tta_snap')\n",
    ",join(DROP2_UREGIONS,'f01234_mc10_tta_snap')\n",
    ",join(PHISEG_UREGIONS,'f01234_tta')\n",
    "\n",
    "]\n",
    "\n",
    "\n",
    "def compute_best_ued(studies):\n",
    "\n",
    "    # Define the base directory\n",
    "    for index, group in enumerate(groups):\n",
    "\n",
    "        base_dir = studies[index]\n",
    "\n",
    "        # Define the subdirectories to iterate through\n",
    "        #subdirs = [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\"] #best th leads to results without \n",
    "        subdirs = [\"7\"]\n",
    "        # Initialize a dictionary to store the results for each patient\n",
    "\n",
    "        results = [] \n",
    "        # Iterate through the subdirectories\n",
    "        for gtv in ['GTV-T', 'GTV-N']:\n",
    "            patient_results = {}\n",
    "            for subdir in subdirs:\n",
    "                # Obtain the UED summary.json file path\n",
    "                ued_path = os.path.join(base_dir, subdir, gtv+\"_union\", \"summary.json\")\n",
    "                # Obtain the FND and FPD summary.json file path\n",
    "                \n",
    "                fpnd_path = os.path.join(base_dir, subdir, gtv, \"summary.json\")\n",
    "                # Check if the summary.json files exist\n",
    "                if os.path.exists(ued_path) and os.path.exists(fpnd_path):\n",
    "                    # Read the UED summary.json file\n",
    "                    with open(ued_path) as f:\n",
    "                        ued_data = json.load(f)\n",
    "                    # Read the FND and FPD summary.json file\n",
    "                    with open(fpnd_path) as f:\n",
    "                        fpnd_data = json.load(f)\n",
    "\n",
    "                    # Iterate through the patients in the UED summary.json file\n",
    "                    for patient_data in ued_data[\"results\"][\"all\"]:\n",
    "                        # Obtain the unique patient ID\n",
    "                        patient_id = os.path.basename(patient_data[\"reference\"]).split(\".nii.gz\")[0]\n",
    "                        # Check if the patient ID already exists in the patient_results dictionary\n",
    "                        if patient_id not in patient_results:\n",
    "                            # Create a new dictionary for the patient ID\n",
    "                            patient_results[patient_id] = {}\n",
    "                        # Obtain the UED value for the patient\n",
    "                        ued_value = patient_data[\"1\"][\"Dice\"]\n",
    "                        ued_volume = patient_data[\"1\"][\"Total Positives Test\"]\n",
    "\n",
    "                        # Check if the UED value is higher than the current value for the patient\n",
    "                        if \"UED\" not in patient_results[patient_id]:\n",
    "                            # Add the UED value to the patient's dictionary\n",
    "                            patient_results[patient_id][\"UED\"]= ued_value\n",
    "                            patient_results[patient_id][\"UED_volume\"]= ued_volume\n",
    "\n",
    "                            patient_results[patient_id][\"UED_th\"]= subdir\n",
    "                        if ued_value > patient_results[patient_id][\"UED\"]:\n",
    "                            # Add the UED value to the patient's dictionary\n",
    "                            patient_results[patient_id][\"UED\"] = ued_value\n",
    "                            patient_results[patient_id][\"UED_volume\"]= ued_volume\n",
    "                            patient_results[patient_id][\"UED_th\"] = subdir\n",
    "                        if ued_volume == 0:\n",
    "                            patient_results[patient_id][\"UED\"]= np.nan\n",
    "                            patient_results[patient_id][\"UED_volume\"]= ued_volume\n",
    "                            patient_results[patient_id][\"UED_th\"]= 0\n",
    "\n",
    "                    for patient_data in fpnd_data[\"results\"][\"all\"]:\n",
    "                        # Obtain the unique patient ID\n",
    "                        patient_id = os.path.basename(patient_data[\"reference\"]).split(\".nii.gz\")[0]\n",
    "                        if patient_id not in patient_results:\n",
    "                            print(\"fError, some thing went wrong {patient_id}\")\n",
    "                            # Create a new dictionary for the patient ID\n",
    "                            break\n",
    "                        # Obtain the FND value for the patient\n",
    "                        fnd_value = patient_data[\"1\"][\"Dice\"]\n",
    "                        fnd_volume = patient_data[\"1\"][\"Total Positives Test\"]\n",
    "                        # Obtain the FPD value for the patient\n",
    "                        fpd_value = patient_data[\"2\"][\"Dice\"]\n",
    "                        fpd_volume = patient_data[\"2\"][\"Total Positives Test\"]\n",
    "\n",
    "                        # Check if the FND value is higher than the current value for the patient\n",
    "                        if \"FND\" not in patient_results[patient_id]:\n",
    "                            # Add the FND value to the patient's dictionary\n",
    "                            patient_results[patient_id][\"FND\"] = fnd_value\n",
    "                            patient_results[patient_id][\"FND_volume\"]= fnd_volume\n",
    "                            patient_results[patient_id][\"FND_th\"] = subdir\n",
    "                        if fnd_value > patient_results[patient_id][\"FND\"]:\n",
    "                            # Add the FND value to the patient's dictionary\n",
    "                            patient_results[patient_id][\"FND\"]= fnd_value\n",
    "                            patient_results[patient_id][\"FND_volume\"]= fnd_volume\n",
    "                            patient_results[patient_id][\"FND_th\"] = subdir\n",
    "                        if fnd_volume == 0:\n",
    "                            patient_results[patient_id][\"FND\"]= np.nan\n",
    "                            patient_results[patient_id][\"FND_volume\"]= fnd_volume\n",
    "                            patient_results[patient_id][\"FND_th\"]= 0\n",
    "\n",
    "                        # Check if the FPD value is higher than the current value for the patient\n",
    "                        if \"FPD\" not in patient_results[patient_id]:\n",
    "                            # Add the FPD value to the patient's dictionary\n",
    "                            patient_results[patient_id][\"FPD\"] = fpd_value\n",
    "                            patient_results[patient_id][\"FPD_volume\"]= fpd_volume\n",
    "                            patient_results[patient_id][\"FPD_th\"]= subdir\n",
    "                        if fpd_value > patient_results[patient_id][\"FPD\"]:\n",
    "                            # Add the FPD value to the patient's dictionary\n",
    "                            patient_results[patient_id][\"FPD\"] = fpd_value\n",
    "                            patient_results[patient_id][\"FPD_volume\"]= fpd_volume\n",
    "                            patient_results[patient_id][\"FPD_th\"]= subdir\n",
    "                        if fpd_volume == 0:\n",
    "                            patient_results[patient_id][\"FPD\"]= np.nan\n",
    "                            patient_results[patient_id][\"FPD_volume\"]= fpd_volume\n",
    "                            patient_results[patient_id][\"FPD_th\"]= 0\n",
    "\n",
    "                        patient_results[patient_id][\"GTV\"] = gtv\n",
    "                        patient_results[patient_id][\"Ucertainty estimation methods\"] = group\n",
    "            results.append(patient_results)\n",
    "        dft = pd.DataFrame(results[0]).T\n",
    "        dfn = pd.DataFrame(results[1]).T\n",
    "        dft.index.names = ['PatientID']\n",
    "        dfn.index.names = ['PatientID']\n",
    "        dft= dft.reset_index(drop=False)\n",
    "        dfn= dfn.reset_index(drop=False)\n",
    "\n",
    "        df_ued = pd.concat([dft, dfn])\n",
    "        df_ued= df_ued.reset_index(drop=True)\n",
    "\n",
    "        if index == 0:\n",
    "            df_ued_all = df_ued\n",
    "        else:\n",
    "            df_ued_all = pd.concat([df_ued_all, df_ued], axis=0)\n",
    "            df_ued_all= df_ued_all.reset_index(drop=True)\n",
    "\n",
    "    return df_ued_all\n",
    "    \n",
    "df_ued_all_internal = compute_best_ued(studies)\n",
    "\n",
    "DROP2_UREGIONS_EXT=\"/data/jintao/nnUNet/nnUNet_results/nnUNet/3d_fullres/Task901_AUH/nnUNetTrainerV2_dropout__nnUNetPlansv2.1/u_regions/Task711_NKI_origin/imagesAll_ct_correct\"\n",
    "NNUNET_UREGIONS_EXT=\"/data/jintao/nnUNet/nnUNet_results/nnUNet/3d_fullres/Task901_AUH/nnUNetTrainerV2__nnUNetPlansv2.1/u_regions/Task711_NKI_origin/imagesAll_ct_correct\"\n",
    "PHISEG_UREGIONS_EXT=\"/data/jintao/nnUNet/nnUNet_results/nnUNet/3d_fullres/Task901_AUH/nnUNetTrainerV2_PhiSeg__nnUNetPlansv2.1/u_regions/Task711_NKI_origin/imagesAll_ct_correct\"\n",
    "\n",
    "studies_ext = [\n",
    "join(NNUNET_UREGIONS_EXT,'f0_tta'),\n",
    "join(NNUNET_UREGIONS_EXT,'f0'),\n",
    "join(DROP2_UREGIONS_EXT,'f0_mc10_tta')\n",
    ",join(NNUNET_UREGIONS_EXT,'f01234_tta')\n",
    "#,join(NNUNET_PMAPS,'f012456_tta')\n",
    ",join(DROP2_UREGIONS_EXT,'f0_tta_snap')\n",
    ",join(DROP2_UREGIONS_EXT,'f01234_mc10_tta_snap')\n",
    ",join(PHISEG_UREGIONS_EXT,'f01234_tta')\n",
    "]\n",
    "df_ued_all_external = compute_best_ued(studies_ext)\n",
    "df_ued_all_external"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FPD\n",
      "GTV-T\n",
      "pvalues before correction:  [8.705748279252395e-16, 0.3541626820157725, 3.288894601514604e-08, 5.475571359566826e-08, 7.184282003004013e-10, 4.3319147819820525e-11]\n",
      "pvalues after correction: [1, 5.223448967551426e-15, 0.3541626820157725, 9.866683480038985e-08, 1.0951142419314835e-07, 2.8737127981047705e-09, 2.1659573908033716e-10]\n",
      "0.32(0.29-0.34)\n",
      "0.21(0.20-0.23)***\n",
      "0.34(0.31-0.36)\n",
      "0.36(0.33-0.38)***\n",
      "0.39(0.36-0.41)***\n",
      "0.40(0.37-0.43)***\n",
      "0.44(0.42-0.47)***\n",
      "GTV-N\n",
      "pvalues before correction:  [2.0191561033704332e-10, 0.19868771777690175, 0.00013254110554204298, 0.016051776293250955, 6.806173276248683e-05, 2.9203693479754667e-10]\n",
      "pvalues after correction: [1, 1.2114936614107111e-09, 0.19868771777690175, 0.0003975706175205228, 0.03184589306433334, 0.0002722191379142826, 1.4601846731348776e-09]\n",
      "0.34(0.30-0.38)\n",
      "0.24(0.21-0.27)***\n",
      "0.33(0.30-0.37)\n",
      "0.36(0.33-0.40)***\n",
      "0.36(0.33-0.39)*\n",
      "0.38(0.35-0.41)***\n",
      "0.47(0.43-0.51)***\n"
     ]
    }
   ],
   "source": [
    "\n",
    "exp= 'UED'\n",
    "exp= 'FND'\n",
    "exp= 'FPD'\n",
    "\n",
    "print_tests(df_ued_all_internal, exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FPD\n",
      "GTV-T\n",
      "pvalues before correction:  [5.7119815668003955e-11, 1.4922206363698853e-33, 3.3244251693779676e-36, 3.302977159797594e-38, 4.3152717533031645e-37, 4.3771866414248054e-33]\n",
      "pvalues after correction: [1, 5.7119815668003955e-11, 4.476661909109656e-33, 1.329770067751187e-35, 1.981786295878556e-37, 2.1576358766515823e-36, 8.754373282849611e-33]\n",
      "0.16(0.15-0.17)\n",
      "0.22(0.21-0.24)***\n",
      "0.34(0.32-0.36)***\n",
      "0.32(0.30-0.33)***\n",
      "0.36(0.34-0.38)***\n",
      "0.37(0.35-0.39)***\n",
      "0.37(0.35-0.40)***\n",
      "GTV-N\n",
      "pvalues before correction:  [2.46237267172169e-07, 2.772638228005272e-26, 1.6277053974326143e-31, 1.5922660989272084e-31, 3.536497583414815e-30, 2.213711843389758e-28]\n",
      "pvalues after correction: [1, 2.46237267172169e-07, 5.545276456010544e-26, 9.55359659356325e-31, 9.55359659356325e-31, 1.414599033365926e-29, 6.641135530169274e-28]\n",
      "0.18(0.17-0.19)\n",
      "0.23(0.21-0.25)***\n",
      "0.34(0.32-0.36)***\n",
      "0.35(0.33-0.37)***\n",
      "0.38(0.36-0.40)***\n",
      "0.37(0.35-0.39)***\n",
      "0.44(0.41-0.46)***\n"
     ]
    }
   ],
   "source": [
    "exp= 'UED'\n",
    "exp= 'FND'\n",
    "exp= 'FPD'\n",
    "\n",
    "print_tests(df_ued_all_external, exp)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import SimpleITK as sitk\n",
    "import numpy as np\n",
    "from multiprocessing import Pool\n",
    "from medpy.metric.binary import hd, asd\n",
    "from scipy.ndimage import binary_erosion\n",
    "from src.utils import save_json, subfiles, join, maybe_mkdir_p, reconstruct_seg_df_from_json, reconstruct_calib_df_from_json, reconstruct_UED_df_from_json\n",
    "\n",
    "def calcualte_target_entropy(arguments, only_seg_roi=False):\n",
    "    th = 0.7\n",
    "    umap_folder , seg_folder,  filename = arguments\n",
    "\n",
    "    # create an dict for data storage\n",
    "\n",
    "    seg_path = join(seg_folder, filename) \n",
    "    umap_path = join(umap_folder, filename.replace(\".nii.gz\", \".npz\")) \n",
    "    pid = filename.replace(\".nii.gz\", \"\")\n",
    "    \n",
    "    \n",
    "    seg = sitk.GetArrayFromImage(sitk.ReadImage(seg_path))\n",
    "    umap = np.load(umap_path)['umap']\n",
    "\n",
    "    resutl_list = []\n",
    "\n",
    "    for target in range(1,3):\n",
    "\n",
    "        entropy_results = {}\n",
    "        entropy_results['PatientID'] = pid\n",
    "\n",
    "        if target == 1:\n",
    "            gtv = 'GTV-T'\n",
    "            \n",
    "        elif target == 2:\n",
    "            gtv = 'GTV-N'\n",
    "\n",
    "        # create an dict for each GTV\n",
    "        entropy_results['GTV'] = gtv\n",
    "    \n",
    "        mask_seg = seg==target\n",
    "\n",
    "        target_umap = umap[target]\n",
    "        mask_umap = target_umap>th\n",
    "\n",
    "        \n",
    "        roi = mask_seg\n",
    "\n",
    "        if not only_seg_roi:\n",
    "            if np.sum(mask_seg) != 0:\n",
    "                union_roi = (mask_seg + mask_umap)\n",
    "                union_roi[union_roi>0] = 1\n",
    "                roi = union_roi\n",
    "        \n",
    "\n",
    "        seg_entropy = target_umap * roi\n",
    "        seg_entropy = seg_entropy[seg_entropy> 0] \n",
    "\n",
    "\n",
    "\n",
    "        if np.sum(mask_seg) == 0:\n",
    "            # no segmentation made for this target (mostly GTV-N)\n",
    "            entropy_results[\"Total Entropy\"] = np.nan \n",
    "            entropy_results[\"Mean Entropy\"] = np.nan \n",
    "            entropy_results[\"Entropy STD\"] = np.nan \n",
    "            entropy_results[\"Entropy Volume\"] = np.nan \n",
    "            entropy_results[\"Entropy Coefficient of Variation\"] = np.nan \n",
    "            entropy_results[\"Logarithm Entropy Coefficient of Variation\"] = np.nan \n",
    "            # entropy_results[\"Uncertainty-Segmentation Hausdorff distance\"] = np.nan \n",
    "            # entropy_results[\"Uncertainty-Segmentation Mean Surface Distance\"] = np.nan \n",
    "\n",
    "        else:\n",
    "            # eros_seg  = binary_erosion(mask_seg, iterations=2).astype(int)\n",
    "            # seg_line = mask_seg.astype(int) - eros_seg\n",
    "            # e_hd  = hd(mask_umap, seg_line)\n",
    "            # e_asd = asd(mask_umap, seg_line)\n",
    "            entropy_mean = np.mean(seg_entropy) \n",
    "            entropy_std = np.std(seg_entropy) \n",
    "            entropy_results[\"Total Entropy\"] = np.sum(seg_entropy)\n",
    "            entropy_results[\"Mean Entropy\"] = entropy_mean\n",
    "            entropy_results[\"Entropy STD\"] = entropy_std\n",
    "            entropy_results[\"Entropy Volume\"] = np.sum(roi) \n",
    "            entropy_results[\"Entropy Coefficient of Variation\"] = entropy_std / (entropy_mean  + 1e-6) # + 1e-6 to avoid divide by 0\n",
    "            entropy_results[\"Logarithm Entropy Coefficient of Variation\"] = np.log(entropy_std / (entropy_mean  + 1e-6)) \n",
    "            # entropy_results[\"Uncertainty-Segmentation Hausdorff distance\"] = e_hd\n",
    "            # entropy_results[\"Uncertainty-Segmentation Mean Surface Distance\"] = e_asd\n",
    "\n",
    "        resutl_list.append(entropy_results)\n",
    "\n",
    "    return resutl_list\n",
    "\n",
    "## directorys for internal  probability maps \n",
    "\n",
    "DROP2_PMAPS=\"/data/jintao/nnUNet/nnUNet_results/nnUNet/3d_fullres/Task901_AUH/nnUNetTrainerV2_dropout__nnUNetPlansv2.1/prob_maps/Task901_AUH/imagesTs\"\n",
    "NNUNET_PMAPS=\"/data/jintao/nnUNet/nnUNet_results/nnUNet/3d_fullres/Task901_AUH/nnUNetTrainerV2__nnUNetPlansv2.1/prob_maps/Task901_AUH/imagesTs\"\n",
    "PH_PMAPS=\"/data/jintao/nnUNet/nnUNet_results/nnUNet/3d_fullres/Task901_AUH/nnUNetTrainerV2_PhiSeg__nnUNetPlansv2.1/prob_maps/Task901_AUH/imagesTs\"\n",
    "PH_GAMM_PMAP=\"/data/jintao/nnUNet/nnUNet_results/nnUNet/3d_fullres/Task901_AUH/nnUNetTrainerV2_PhiSeg_gamma__nnUNetPlansv2.1/prob_maps/Task901_AUH/imagesTs\"\n",
    "\n",
    "\n",
    "groups = {'Baseline': join(NNUNET_PMAPS,'f0_tta')\n",
    "          ,'No TTA': join(NNUNET_PMAPS,'f0')\n",
    "          ,'MC Dropout': join(DROP2_PMAPS,'f0_mc10_tta')\n",
    "          ,'Ensemble': join(NNUNET_PMAPS,'f01234_tta')\n",
    "          ,'Snapshots':join(DROP2_PMAPS,'f0_tta_snap')\n",
    "          ,\"Complex\":join(DROP2_PMAPS,'f01234_mc10_tta_snap')\n",
    "          ,'PhiSeg': join(PH_PMAPS,'f01234_tta')\n",
    "          }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Task = 'Complex' #Complex #PhiSeg #External #Baseline #Snapshots\n",
    "    ## complex\n",
    "seg_folder = groups[Task]\n",
    "umap_folder = seg_folder.replace(\"prob_maps\",\"umaps\")\n",
    "\n",
    "## external\n",
    "# seg_folder = '/data/jintao/nnUNet/nnUNet_results/nnUNet/3d_fullres/Task901_AUH/nnUNetTrainerV2_dropout__nnUNetPlansv2.1/prob_maps/Task711_NKI_origin/imagesAll_ct_correct/f0_mc10_tta' #f01234_mc10_tta'\n",
    "# umap_folder =  '/data/jintao/nnUNet/nnUNet_results/nnUNet/3d_fullres/Task901_AUH/nnUNetTrainerV2_dropout__nnUNetPlansv2.1/umaps/Task711_NKI_origin/imagesAll_ct_correct/f0_mc10_tta' #f01234_mc10_tta'\n",
    "\n",
    "seg_files_in = subfiles(seg_folder, suffix=\".nii.gz\", join=False) \n",
    "umaps = [umap_folder] * len(seg_files_in)\n",
    "segs = [seg_folder] * len(seg_files_in)\n",
    "\n",
    "p = Pool(128)\n",
    "entropy_results=  p.map(calcualte_target_entropy, zip(umaps, segs, seg_files_in))\n",
    "p.close()\n",
    "p.join()\n",
    "#=========================================#\n",
    "entropy_t = []\n",
    "entropy_n = []\n",
    "for result in entropy_results:\n",
    "    entropy_t.append(result[0])\n",
    "    entropy_n.append(result[1])\n",
    "entropy_dft = pd.DataFrame(entropy_t)\n",
    "entropy_dfn = pd.DataFrame(entropy_n)\n",
    "\n",
    "entropy_df_all = pd.concat([entropy_dft, entropy_dfn], axis=0)\n",
    "entropy_df_all = entropy_df_all.reset_index(drop=False)\n",
    "\n",
    "complex_all_data = all_seg_internal[all_seg_internal[\"Ucertainty estimation methods\"]==Task]\n",
    "complex_all_data_entropy = pd.merge(complex_all_data, entropy_df_all, how=\"inner\", on=[\"PatientID\", \"GTV\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
